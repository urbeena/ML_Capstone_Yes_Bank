## ğŸ“ˆ ML Capstone â€“ Yes Bank Stock Price Prediction

This project implements an **end-to-end Machine Learning pipeline** to predict **Yes Bank stock prices** using historical market data.
It follows **industry-standard project structuring**, **modular design**, **logging**, **exception handling**, and **MLOps-ready pipelines**.

---

## ğŸš€ Project Highlights

* End-to-end ML lifecycle: ingestion â†’ transformation â†’ training â†’ evaluation â†’ deployment
* Clean, modular, production-ready folder structure
* Centralized logging & custom exception handling
* YAML-based configuration management
* Streamlit app for real-time predictions

---

## ğŸ“‚ Project Structure

```
ML_Capstone_Yes_Bank/
â”‚
â”œâ”€â”€ Yes_Bank/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ entity/
â”‚   â”œâ”€â”€ exception/
â”‚   â”œâ”€â”€ logging/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”œâ”€â”€ artifacts/
â”œâ”€â”€ logs/
â”œâ”€â”€ main.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“ Folder-wise Documentation

---

## 1ï¸âƒ£ `Yes_Bank/components/`

Contains the **core ML logic**, each module handling one stage of the pipeline.

| File                     | Description                                    |
| ------------------------ | ---------------------------------------------- |
| `data_ingestion.py`      | Loads raw dataset and splits into train/test   |
| `data_transformation.py` | Feature engineering, scaling, preprocessing    |
| `model_trainer.py`       | Trains multiple ML models and selects best one |
|                          | Evaluates trained model using metrics          |
|                          | Pushes the final model for deployment          |

---

## 2ï¸âƒ£ `Yes_Bank/config/`

Configuration-driven pipeline setup.



---

## 3ï¸âƒ£ `Yes_Bank/entity/`

Defines **dataclasses** for configuration and artifact tracking.

| File                            | Description                       |
| ------------------------------- | --------------------------------- |
| `data_ingestion_entity.py`      | Ingestion config & artifacts      |
| `data_transformation_entity.py` | Transformation config & artifacts |
| `model_trainer_entity.py`       | Model training config             |
|                                 | Evaluation results                |

âœ”ï¸ Enables clean data flow between pipeline stages

---

## 4ï¸âƒ£ `Yes_Bank/exception/`

Centralized custom exception handling.

| File           | Description                                  |
| -------------- | -------------------------------------------- |
| `exception.py` | CustomException class with traceback support |

---

## 5ï¸âƒ£ `Yes_Bank/logging/`

Project-wide logging setup.

| File        | Description                             |
| ----------- | --------------------------------------- |
| `logger.py` | Logger configuration and log formatting |

ğŸ“Œ Logs stored automatically in `/logs`

---

## 6ï¸âƒ£ `Yes_Bank/pipeline/`

Orchestrates ML workflows.

| File                     | Description                       |
| ------------------------ | --------------------------------- |
| `training_pipeline.py`   | Runs full training pipeline       |
| `prediction_pipeline.py` | Loads model and makes predictions |

---

## 7ï¸âƒ£ `Yes_Bank/utils/`

Helper functions and reusable logic.

| File            | Description                         |
| --------------- | ----------------------------------- |
| `main_utils.py` | Common utility functions            |
| `ml_utils.py`   | Prediction & model helper utilities |

---

## 8ï¸âƒ£ `data/`

Contains the raw dataset.

| File           | Description                    |
| -------------- | ------------------------------ |
| `yes_bank.csv` | Historical Yes Bank stock data |

---

## 9ï¸âƒ£ `artifacts/`

Stores outputs from each pipeline stage.

```
artifacts/
â”œâ”€â”€ data_ingestion/
â”œâ”€â”€ data_transformation/
â”œâ”€â”€ model_trainer/
â””â”€â”€ model_evaluation/
```

âœ”ï¸ Makes pipeline reproducible & debuggable

---

## ğŸ”Ÿ `logs/`

Auto-generated logs for debugging & monitoring.

---

## ğŸ“Œ Root Files

| File               | Purpose                           |
| ------------------ | --------------------------------- |
| `main.py`          | Entry point for training pipeline |
| `app.py`           | Streamlit app for prediction      |
| `requirements.txt` | Project dependencies              |
| `setup.py`         | Package setup for deployment      |
| `.gitignore`       | Git ignored files                 |

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Install Dependencies

```bash
ENVIRONMENT SETUP (ALREADY IMPLEMENTED)

Step 1: Create virtual environment

conda create -p venv python=3.8 -y

Step 2: Activate virtual environment

conda activate venv/

Step 3: Install dependencies

pip install -r requirements.txt

Step 4: Install project in editable mode

pip install -e .

Why pip install -e . ?

â€¢ Makes the project importable as a package
â€¢ Prevents ModuleNotFoundError
â€¢ Automatically reflects code changes
â€¢ Follows real-world ML/MLOps standards```

### 2ï¸âƒ£ Train the Model

```bash
python main.py
```

### 3ï¸âƒ£ Run Prediction App

```bash
streamlit run app.py
```

---

## ğŸ“Š ML Workflow

```
Data Ingestion â†’ Data Transformation â†’ Model Training â†’ Model Evaluation â†’ Deployment
```



## âœ¨ Author

**Urbeena Rashid**
ML Capstone Project

---

â­ If you like this project, donâ€™t forget to star the repository!
