# ğŸ“ˆ ML Capstone â€“ Yes Bank Stock Price Prediction

This repository contains an **end-to-end Machine Learning pipeline** for predicting **Yes Bank stock prices** using historical data.  
The project is designed following **industry-standard ML & MLOps practices**, including modular coding, configuration-driven pipelines, logging, exception handling, and artifact management.

Each pipeline stage is implemented **step-by-step**, with:
- A config file
- A config entity
- A config artifact

This makes the project **scalable, maintainable, and production-ready**.

---

## ğŸ“‚ Project Structure

ML_Capstone_Yes_Bank/
â”‚
â”œâ”€â”€ Yes_Bank/
â”‚ â”œâ”€â”€ components/ # Core ML pipeline components
â”‚ â”‚ â”œâ”€â”€ data_ingestion.py
â”‚ â”‚ â”œâ”€â”€ data_transformation.py
â”‚ â”‚ â”œâ”€â”€ model_trainer.py
â”‚ â”‚ â”œâ”€â”€ model_evaluation.py
â”‚ â”‚ â””â”€â”€ model_pusher.py
â”‚ â”‚
â”‚ â”œâ”€â”€ config/ # Configuration files (YAML / constants)
â”‚ â”œâ”€â”€ entity/ # Config & artifact entities
â”‚ â”œâ”€â”€ exception/ # Custom exception handling
â”‚ â”œâ”€â”€ logging/ # Centralized logging configuration
â”‚ â”œâ”€â”€ pipeline/ # Training & prediction pipelines
â”‚ â”œâ”€â”€ utils/ # Utility functions
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ data/ # Raw dataset
â”œâ”€â”€ artifacts/ # Output artifacts of each pipeline stage
â”œâ”€â”€ logs/ # Auto-generated log files
â”œâ”€â”€ venv/ # Virtual environment (ignored in git)
â”‚
â”œâ”€â”€ main.py # Training pipeline execution
â”œâ”€â”€ app.py # Prediction / deployment entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

yaml
Copy code

---

## âš™ï¸ Environment Setup (Step-by-Step)

### 1ï¸âƒ£ Create Virtual Environment

```bash
conda create -p venv python=3.8 -y
2ï¸âƒ£ Activate the Environment
bash
Copy code
conda activate venv/
3ï¸âƒ£ Install Project in Editable Mode
bash
Copy code
pip install -e .
ğŸ§  Why pip install -e .?
Installing the project in editable mode:

Makes the project importable as a package

Prevents ModuleNotFoundError

Automatically reflects code changes

Follows real-world ML/MLOps standards

ğŸ”„ Machine Learning Pipeline â€“ Step-by-Step Implementation
âœ… Step 1: Data Ingestion
Loads raw Yes Bank stock data

Splits data into training and testing sets

Saves outputs as artifacts

ğŸ“ Artifacts:

bash
Copy code
artifacts/data_ingestion/
âœ” Config file created
âœ” Config entity defined
âœ” Data ingestion artifact generated

âœ… Step 2: Data Transformation
Handles missing values

Feature engineering

Scaling and preprocessing

Saves transformed data and preprocessing object

ğŸ“ Artifacts:

bash
Copy code
artifacts/data_transformation/
âœ” Config updated
âœ” Transformation entity created
âœ” Transformation artifacts generated

âœ… Step 3: Model Trainer
Trains multiple regression models

Evaluates model performance

Selects the best-performing model

Saves trained model object

ğŸ“ Artifacts:

bash
Copy code
artifacts/model_trainer/
âœ” Model trainer config implemented
âœ” Model trainer entity created
âœ” Trained model artifact saved